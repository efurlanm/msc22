{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF NUMBA SEQ 66 k\n",
    "\n",
    "Preloaded:\n",
    "\n",
    "    source /scratch/xxx/rfas/env2/etc/profile.d/conda.sh\n",
    "    conda activate /scratch/xxxx/rfas/env2\n",
    "    module load openmpi/gnu/4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rfas6.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rfas6.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.io import arff\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics    \n",
    "from numba import jit, objmode\n",
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "@jit(forceobj=True)\n",
    "def rfcsf(trainset, testset) :\n",
    "    data = arff.loadarff(trainset)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    df = df.replace(b'N', 0)\n",
    "    df = df.replace(b'Y', 1)\n",
    "    df['class'] = df['class'].str.decode('utf-8').fillna(df['class'])\n",
    "    y_train = df['class']\n",
    "    X_train = df.drop(columns=['class'])\n",
    "    imp = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "    df2 = pd.DataFrame(imp.fit_transform(X_train))\n",
    "    df2.columns = X_train.columns\n",
    "    df2.index = X_train.index\n",
    "    X_train = df2\n",
    "\n",
    "    datat = arff.loadarff(testset)\n",
    "    df = pd.DataFrame(datat[0])\n",
    "    df = df.replace(b'N', 0)\n",
    "    df = df.replace(b'Y', 1)\n",
    "    df['class'] = df['class'].str.decode('utf-8').fillna(df['class'])\n",
    "    y_test = df['class']\n",
    "    X_test = df.drop(columns = ['class'])\n",
    "    imp = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "    df2 = pd.DataFrame(imp.fit_transform(X_test))\n",
    "    df2.columns = X_test.columns\n",
    "    df2.index = X_test.index\n",
    "    X_test = df2\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_test  = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accu = metrics.accuracy_score(y_train, y_pred_train, normalize = False)\n",
    "    trtrsi = y_train.size\n",
    "    trperr = ((trtrsi - accu) / (trtrsi)) * 100\n",
    "    trkapp = metrics.cohen_kappa_score(y_train, y_pred_train)\n",
    "    \n",
    "    accu = metrics.accuracy_score(y_test, y_pred_test, normalize = False)\n",
    "    tetrsi = y_test.size\n",
    "    teperr = ((tetrsi - accu) / (tetrsi)) * 100\n",
    "    tekapp = metrics.cohen_kappa_score(y_test, y_pred_test)\n",
    "    \n",
    "    return trtrsi, trperr, trkapp, tetrsi, teperr, tekapp\n",
    "\n",
    "# main\n",
    "trainset = \"datasets/asteroid-train-66k.arff\"\n",
    "testset  = \"datasets/asteroid-test-34k.arff\"\n",
    "trtrsi, trperr, trkapp, tetrsi, teperr, tekapp = rfcsf(trainset, testset)\n",
    "t1 = time() - t0\n",
    "print(f'Trainset classification error is {trperr:.2f}% ',\n",
    "      f'of {trtrsi} (kappa: {trkapp:.4f})')\n",
    "print(f' Testset classification error is {teperr:.2f}% ',\n",
    "      f'of {tetrsi} (kappa: {tekapp:.4f})')\n",
    "print(f\"T: {t1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python rfas6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp rfas6* /scratch${PWD#\"/prj\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rfas6.srm\n"
     ]
    }
   ],
   "source": [
    "%%writefile rfas6.srm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name rfas6        # Job name\n",
    "#SBATCH --partition cpu_small  # Select partition\n",
    "#SBATCH --ntasks=1             # Total tasks\n",
    "#SBATCH --time=00:05:00        # Limit execution time\n",
    "#SBATCH --exclusive            # Exclusive acccess to nodes\n",
    "\n",
    "echo '========================================'\n",
    "echo '- Job ID:' $SLURM_JOB_ID\n",
    "echo '- Tasks per node:' $SLURM_NTASKS_PER_NODE\n",
    "echo '- # of nodes in the job:' $SLURM_JOB_NUM_NODES\n",
    "echo '- # of tasks:' $SLURM_NTASKS\n",
    "echo '- Dir from which sbatch was invoked:' ${SLURM_SUBMIT_DIR##*/}\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "echo -n '- List of nodes allocated to the job: '\n",
    "nodeset -e $SLURM_JOB_NODELIST\n",
    "\n",
    "# Environment\n",
    "cd\n",
    "dir=/scratch${PWD#\"/prj\"}\n",
    "cd $dir\n",
    "source $dir/env2/etc/profile.d/conda.sh\n",
    "conda activate $dir/env2\n",
    "cd rf\n",
    "\n",
    "# Executable config\n",
    "EXEC=\"python rfas6.py\"\n",
    "\n",
    "# Start\n",
    "echo '$ srun --mpi=pmi2 -n' $SLURM_NTASKS ${EXEC##*/}\n",
    "echo '-- output -----------------------------'\n",
    "srun --mpi=pmi2 -n $SLURM_NTASKS $EXEC\n",
    "echo '~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1347039\n",
      "Submitted batch job 1347040\n",
      "Submitted batch job 1347041\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sbatch rfas6.srm\n",
    "sbatch rfas6.srm\n",
    "sbatch rfas6.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 1347039\n",
      "- Tasks per node:\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1439\n",
      "$ srun --mpi=pmi2 -n 1 python rfas6.py\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.01%  of 34000 (kappa: 0.9994)\n",
      "T: 25.0529\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "========================================\n",
      "- Job ID: 1347040\n",
      "- Tasks per node:\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1440\n",
      "$ srun --mpi=pmi2 -n 1 python rfas6.py\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 25.3204\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "========================================\n",
      "- Job ID: 1347041\n",
      "- Tasks per node:\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1441\n",
      "$ srun --mpi=pmi2 -n 1 python rfas6.py\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 24.5752\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat /scratch${PWD#\"/prj\"}/slurm-1347039.out\n",
    "cat /scratch${PWD#\"/prj\"}/slurm-1347040.out\n",
    "cat /scratch${PWD#\"/prj\"}/slurm-1347041.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! squeue -u $(whoami) -h -t pending,running -r | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n"
     ]
    }
   ],
   "source": [
    "! squeue --partition=cpu_small -h -t pending,running -r | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! squeue -n rfas6 -o \"%.18i  %.9P  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID  PARTITION  ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue -n rfas6 -o \"%.18i  %.9P  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
