{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF PYTHON SEQ 66 k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rfps6.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rfps6.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.io import arff\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "t = time()\n",
    "\n",
    "data = arff.loadarff(sys.argv[1])\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.replace(b'N', 0)\n",
    "df = df.replace(b'Y', 1)\n",
    "df['class'] = df['class'].str.decode('utf-8').fillna(df['class'])\n",
    "y_train = df['class']\n",
    "X_train = df.drop(columns=['class'])\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "df2 = pd.DataFrame(imp.fit_transform(X_train))\n",
    "df2.columns = X_train.columns\n",
    "df2.index = X_train.index\n",
    "X_train = df2\n",
    "\n",
    "datat = arff.loadarff(sys.argv[2])\n",
    "df = pd.DataFrame(datat[0])\n",
    "df = df.replace(b'N', 0)\n",
    "df = df.replace(b'Y', 1)\n",
    "df['class'] = df['class'].str.decode('utf-8').fillna(df['class'])\n",
    "y_test = df['class']\n",
    "X_test = df.drop(columns = ['class'])\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "df2 = pd.DataFrame(imp.fit_transform(X_test))\n",
    "df2.columns = X_test.columns\n",
    "df2.index = X_test.index\n",
    "X_test = df2\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_test  = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "accu = metrics.accuracy_score(y_train, y_pred_train, normalize = False)\n",
    "trsi = y_train.size\n",
    "perr = ((trsi - accu) / (trsi)) * 100\n",
    "kapp = metrics.cohen_kappa_score(y_train, y_pred_train)\n",
    "print(f'Trainset classification error is {perr:.2f}% ',\n",
    "      f'of {trsi} (kappa: {kapp:.4f})')\n",
    "accu = metrics.accuracy_score(y_test, y_pred_test, normalize = False)\n",
    "trsi = y_test.size\n",
    "perr = ((trsi - accu) / (trsi)) * 100\n",
    "kapp = metrics.cohen_kappa_score(y_test, y_pred_test)\n",
    "print(f' Testset classification error is {perr:.2f}% ',\n",
    "      f'of {trsi} (kappa: {kapp:.4f})')\n",
    "\n",
    "t = time() - t\n",
    "print(f\"T: {t:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 21.1073 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tCommand being timed: \"python rfps6.py /scratch/ampemi/eduardo.miranda2/rf/datasets/asteroid-train-66k.arff /scratch/ampemi/eduardo.miranda2/rf/datasets/asteroid-test-34k.arff\"\n",
      "\tUser time (seconds): 21.55\n",
      "\tSystem time (seconds): 1.68\n",
      "\tPercent of CPU this job got: 36%\n",
      "\tElapsed (wall clock) time (h:mm:ss or m:ss): 1:02.99\n",
      "\tAverage shared text size (kbytes): 0\n",
      "\tAverage unshared data size (kbytes): 0\n",
      "\tAverage stack size (kbytes): 0\n",
      "\tAverage total size (kbytes): 0\n",
      "\tMaximum resident set size (kbytes): 246668\n",
      "\tAverage resident set size (kbytes): 0\n",
      "\tMajor (requiring I/O) page faults: 0\n",
      "\tMinor (reclaiming a frame) page faults: 207611\n",
      "\tVoluntary context switches: 13540\n",
      "\tInvoluntary context switches: 27\n",
      "\tSwaps: 0\n",
      "\tFile system inputs: 421168\n",
      "\tFile system outputs: 0\n",
      "\tSocket messages sent: 0\n",
      "\tSocket messages received: 0\n",
      "\tSignals delivered: 0\n",
      "\tPage size (bytes): 4096\n",
      "\tExit status: 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "RF=/scratch${PWD#/prj}\n",
    "SCR=${RF%/rf}\n",
    "source $SCR/env2/etc/profile.d/conda.sh\n",
    "conda activate $SCR/env2\n",
    "/usr/bin/time -v python rfps6.py $RF/datasets/asteroid-train-66k.arff $RF/datasets/asteroid-test-34k.arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy to scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp rfps6.py /scratch${PWD#/prj}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slurm script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rfps6.srm\n"
     ]
    }
   ],
   "source": [
    "%%writefile rfps6.srm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name rfps6       # Job name\n",
    "#SBATCH --partition cpu_small  # Select partition\n",
    "#SBATCH --ntasks=1             # Total tasks(CPUs)\n",
    "#SBATCH --time=00:05:00        # Limit execution time\n",
    "#SBATCH --exclusive            # Exclusive acccess to nodes\n",
    "\n",
    "echo '========================================'\n",
    "echo '- Job ID:' $SLURM_JOB_ID\n",
    "echo '- # of nodes in the job:' $SLURM_JOB_NUM_NODES\n",
    "echo '- # of tasks:' $SLURM_NTASKS\n",
    "echo '- Dir from which sbatch was invoked:' ${SLURM_SUBMIT_DIR##*/}\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "echo -n '- List of nodes allocated to the job: '\n",
    "nodeset -e $SLURM_JOB_NODELIST\n",
    "\n",
    "# Environment\n",
    "echo '-- modules ----------------------------'\n",
    "RF=/scratch${PWD#/prj}\n",
    "SCR=${RF%/rf}\n",
    "source $SCR/env2/etc/profile.d/conda.sh\n",
    "conda activate $SCR/env2\n",
    "cd $RF\n",
    "\n",
    "# Executable\n",
    "DT1=asteroid-train-66k.arff\n",
    "DT2=asteroid-test-34k.arff\n",
    "EXEC=\"python rfps6.py datasets/\"$DT1\" datasets/\"$DT2\n",
    "\n",
    "# Start\n",
    "echo '-- run --------------------------------'\n",
    "echo '$ srun -n' $SLURM_NTASKS $EXEC\n",
    "echo '-- output -----------------------------'\n",
    "srun -n $SLURM_NTASKS $EXEC\n",
    "echo '~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1348476\n"
     ]
    }
   ],
   "source": [
    "! sbatch --partition cpu_dev --time=00:05:00 --ntasks=1 rfps6.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   JOBID  PARTITION  NAME ST  TIME NODES CPUS\n",
      " 1348476    cpu_dev rfps6 PD  0:00     1    1\n"
     ]
    }
   ],
   "source": [
    "! squeue --name=rfps6 --partition=cpu_dev --format=\"%.8i  %.9P %.5j %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   JOBID  PARTITION  NAME ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue --name=rfps6 --partition=cpu_dev --format=\"%.8i  %.9P %.5j %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 1348476\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1244\n",
      "-- modules ----------------------------\n",
      "-- run --------------------------------\n",
      "$ srun -n 1 python rfps6.py datasets/asteroid-train-66k.arff datasets/asteroid-test-34k.arff\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 23.4568 s\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "! cat /scratch${PWD#\"/prj\"}/slurm-1348476.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1348480\n",
      "Submitted batch job 1348481\n",
      "Submitted batch job 1348482\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sbatch rfps6.srm\n",
    "sbatch rfps6.srm\n",
    "sbatch rfps6.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 1348480\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1286\n",
      "-- modules ----------------------------\n",
      "-- run --------------------------------\n",
      "$ srun -n 1 python rfps6.py datasets/asteroid-train-66k.arff datasets/asteroid-test-34k.arff\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 25.8629 s\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "========================================\n",
      "- Job ID: 1348481\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1286\n",
      "-- modules ----------------------------\n",
      "-- run --------------------------------\n",
      "$ srun -n 1 python rfps6.py datasets/asteroid-train-66k.arff datasets/asteroid-test-34k.arff\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 26.7041 s\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "========================================\n",
      "- Job ID: 1348482\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks: 1\n",
      "- Dir from which sbatch was invoked: rf\n",
      "- List of nodes allocated to the job: sdumont1286\n",
      "-- modules ----------------------------\n",
      "-- run --------------------------------\n",
      "$ srun -n 1 python rfps6.py datasets/asteroid-train-66k.arff datasets/asteroid-test-34k.arff\n",
      "-- output -----------------------------\n",
      "Trainset classification error is 0.00%  of 66000 (kappa: 1.0000)\n",
      " Testset classification error is 0.00%  of 34000 (kappa: 0.9997)\n",
      "T: 24.4286 s\n",
      "~~ end ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat /scratch${PWD#\"/prj\"}/slurm-1348480.out\n",
    "cat /scratch${PWD#\"/prj\"}/slurm-1348481.out\n",
    "cat /scratch${PWD#\"/prj\"}/slurm-1348482.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "! squeue -u $(whoami) -h -r | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "! squeue --partition=cpu_small -h -r | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TIME     JOBID  PARTITION  NAME ST  TIME NODES CPUS\n",
      "N/A   1348480  cpu_small rfps6 PD  0:00     1    1\n",
      "N/A   1348481  cpu_small rfps6 PD  0:00     1    1\n",
      "N/A   1348482  cpu_small rfps6 PD  0:00     1    1\n"
     ]
    }
   ],
   "source": [
    "! squeue --start --user=$(whoami) --name=rfps6 -o \"%S  %.8i  %.9P %.5j %.2t %.5M %.5D %.4C\" --sort \"i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TIME     JOBID  PARTITION  NAME ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue --start --user=$(whoami) --name=rfps6 -o \"%S  %.8i  %.9P %.5j %.2t %.5M %.5D %.4C\" --sort \"i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   JobName      NCPUS   NNodes     MaxRSS    MaxRSSNode               Start    Elapsed    CPUTime \n",
      "---------- ---------- -------- ---------- ------------- ------------------- ---------- ---------- \n",
      "     rfps6         24        1                          2021-09-15T00:56:05   00:02:09   00:51:36 \n",
      "     batch         24        1      9304K   sdumont1286 2021-09-15T00:56:05   00:02:09   00:51:36 \n",
      "    python          1        1    233104K   sdumont1286 2021-09-15T00:56:24   00:01:50   00:01:50 \n"
     ]
    }
   ],
   "source": [
    "! sacct --jobs=1348480 --format=jobname,ncpus,nnodes,maxrss,maxrssnode%13,start,elapsed,cputime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeName=sdumont1286 Arch=x86_64 CoresPerSocket=12\n",
      "   CPUAlloc=24 CPUErr=0 CPUTot=24 CPULoad=24.05\n",
      "   AvailableFeatures=(null)\n",
      "   ActiveFeatures=(null)\n",
      "   Gres=(null)\n",
      "   NodeAddr=sdumont1286 NodeHostName=sdumont1286 Version=17.02\n",
      "   OS=Linux RealMemory=64000 AllocMem=64000 FreeMem=55681 Sockets=2 Boards=1\n",
      "   State=ALLOCATED ThreadsPerCore=1 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A\n",
      "   Partitions=cpu,cpu_small,cpu_dev,cpu_scal,cpu_long \n",
      "   BootTime=2021-08-12T11:50:36 SlurmdStartTime=2021-08-12T13:12:37\n",
      "   CfgTRES=cpu=24,mem=62.50G\n",
      "   AllocTRES=cpu=24,mem=62.50G\n",
      "   CapWatts=n/a\n",
      "   Socket_CapWatts=n/a\n",
      "   CurrentWatts=74 LowestJoules=830 ConsumedJoules=341341133\n",
      "   ExtSensorsJoules=n/s ExtSensorsWatts=0 ExtSensorsTemp=n/s\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! scontrol show node sdumont1286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
