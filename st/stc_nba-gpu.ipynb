{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba-GPU\n",
    "\n",
    "codigo baseado em:\n",
    "\n",
    "https://nyu-cds.github.io/python-numba/05-cuda/\n",
    "\n",
    "https://numba.pydata.org/numba-doc/dev/cuda/kernels.html\n",
    "\n",
    "Fila | Wall-clock máximo (em horas) | Número mínimo de nós (núcleos+ dispositivos) | Número máximo de nós (núcleos+ dispositivos) | Número máximo de tarefas em execução por usuário | Número máximo de tarefas em fila por usuário\n",
    "- | - | - | - | - | -\n",
    "nvidia_small | 1 | 1 (24+2) | 20 (480+40) | 4 | 24\n",
    "nvidia_dev | 0:20 | 1 (24+2) | 4 (96+8) | 1 | 1\n",
    "sequana_gpu | 96 | 1 (48+4) | 21 (1008+84) | 4 | 24\n",
    "\n",
    "\n",
    "    ssh sdumont18\n",
    "    Xeon Gold 6152, 22 núcleos, 44 threads, total 88 \"cpus\", 754 G RAM\n",
    "    4x Tesla V100\n",
    "    \n",
    "    module load sequana/current\n",
    "    module load sdbase\n",
    "    module load anaconda3/2018.12\n",
    "    conda activate --stack /scratch/ampemi/pedro.santos2/anaconda3/envs/dscience\n",
    "    export NUMBAPRO_NVVM=/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
    "    export NUMBAPRO_LIBDEVICE=/usr/local/cuda-10.1/nvvm/libdevice/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.12 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                88\n",
      "On-line CPU(s) list:   0-87\n",
      "Thread(s) per core:    2\n",
      "Core(s) per socket:    22\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 85\n",
      "Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz\n",
      "Stepping:              4\n",
      "CPU MHz:               2101.000\n",
      "CPU max MHz:           2101.0000\n",
      "CPU min MHz:           1000.0000\n",
      "BogoMIPS:              4200.00\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              1024K\n",
      "L3 cache:              30976K\n",
      "NUMA node0 CPU(s):     0-21,44-65\n",
      "NUMA node1 CPU(s):     22-43,66-87\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_ppin intel_pt ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke md_clear spec_ctrl intel_stibp flush_l1d\n"
     ]
    }
   ],
   "source": [
    "! lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       791009752 kB\n"
     ]
    }
   ],
   "source": [
    "! cat /proc/meminfo | grep MemTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 30 19:19:29 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    30W / 250W |    125MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    26W / 250W |     15MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    25W / 250W |     15MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    26W / 250W |     15MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     62486      G   /usr/bin/X                                    39MiB |\n",
      "|    0     62553      G   /usr/bin/gnome-shell                          85MiB |\n",
      "|    1     62486      G   /usr/bin/X                                    14MiB |\n",
      "|    2     62486      G   /usr/bin/X                                    14MiB |\n",
      "|    3     62486      G   /usr/bin/X                                    14MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>, <Managed Device 1>, <Managed Device 2>, <Managed Device 3>\n"
     ]
    }
   ],
   "source": [
    "# verificando se Cuda está ativo\n",
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat=1500.0000 | Tempo=8.0218\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numba import cuda, jit, prange\n",
    "\n",
    "@cuda.jit\n",
    "def st3(a1, a2):\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = a2[i,j]/2.0+(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1])/8.0\n",
    "\n",
    "def calc3(anew, aold, heat, sizeEnd, niters, nsources, sources, energy,\n",
    "          blocks_per_grid, threads_per_block):\n",
    "    for iters in range(0, niters, 2):\n",
    "        st3[blocks_per_grid, threads_per_block](anew, aold)\n",
    "        for i in range(0, nsources) :\n",
    "            anew[sources[i,0], sources[i,1]] += energy    # heat source\n",
    "        st3[blocks_per_grid, threads_per_block](aold, anew)\n",
    "        for i in range(0, nsources):  \n",
    "            aold[sources[i,0], sources[i,1]] += energy    # heat source        \n",
    "\n",
    "#def par_cuda():\n",
    "n            = 4800    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 500     # number of iterations\n",
    "nsources     = 3       # sources of energy\n",
    "size         = n + 2   # plus the ghost zone\n",
    "sizeEnd      = n + 1\n",
    "\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((size, size), np.float64)\n",
    "aold         = np.zeros((size, size), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3,2), np.int32)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "heat         = 0       # system total heat sum\n",
    "\n",
    "# copy the arrays to the device\n",
    "anew_global_mem = cuda.to_device(anew)\n",
    "aold_global_mem = cuda.to_device(aold)\n",
    "\n",
    "# configure blocks & grids\n",
    "# set the number of threads in a block\n",
    "threads_per_block = (8, 8)\n",
    "# calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "t = time()\n",
    "# main calc\n",
    "calc3(anew_global_mem, aold_global_mem, heat,\n",
    "    sizeEnd, niters, nsources, sources, energy,\n",
    "    blocks_per_grid, threads_per_block)\n",
    "\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "\n",
    "for j in range(1, sizeEnd):\n",
    "    for i in range(1, sizeEnd):\n",
    "        heat = heat + aold[i,j]\n",
    "t = time() - t\n",
    "\n",
    "# show the result if desired\n",
    "print(\"Heat=%.4f | Tempo=%.4f\" % (heat, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REV2, grava um arquivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sngr2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sngr2.py\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numba import cuda, jit, prange\n",
    "\n",
    "@cuda.jit\n",
    "def st3(a1, a2):\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = a2[i,j]/2.0+(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1])/8.0\n",
    "\n",
    "def calc3(anew, aold, heat, sizeEnd, niters, nsources, sources, energy,\n",
    "          blocks_per_grid, threads_per_block):\n",
    "    for iters in range(0, niters, 2):\n",
    "        st3[blocks_per_grid, threads_per_block](anew, aold)\n",
    "        for i in range(0, nsources) :\n",
    "            anew[sources[i,0], sources[i,1]] += energy    # heat source\n",
    "        st3[blocks_per_grid, threads_per_block](aold, anew)\n",
    "        for i in range(0, nsources):  \n",
    "            aold[sources[i,0], sources[i,1]] += energy    # heat source        \n",
    "\n",
    "#def par_cuda():\n",
    "n            = 4800    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 500     # number of iterations\n",
    "nsources     = 3       # sources of energy\n",
    "size         = n + 2   # plus the ghost zone\n",
    "sizeEnd      = n + 1\n",
    "\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((size, size), np.float64)\n",
    "aold         = np.zeros((size, size), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3,2), np.int32)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "heat         = 0       # system total heat sum\n",
    "\n",
    "# copy the arrays to the device\n",
    "anew_global_mem = cuda.to_device(anew)\n",
    "aold_global_mem = cuda.to_device(aold)\n",
    "\n",
    "# configure blocks & grids\n",
    "# set the number of threads in a block\n",
    "threads_per_block = (8, 8)\n",
    "# calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "t = time()\n",
    "# main calc\n",
    "calc3(anew_global_mem, aold_global_mem, heat,\n",
    "    sizeEnd, niters, nsources, sources, energy,\n",
    "    blocks_per_grid, threads_per_block)\n",
    "\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "\n",
    "for j in range(1, sizeEnd):\n",
    "    for i in range(1, sizeEnd):\n",
    "        heat = heat + aold[i,j]\n",
    "t = time() - t\n",
    "\n",
    "# show the result if desired\n",
    "print(\"Heat=%.4f | Tempo=%.4f\" % (heat, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REV2 : rodando 4x no sdumont18\n",
    "\n",
    "- ambiente antigo não funciona mais, rodando agora com:\n",
    "```\n",
    "SCR=/scratch${PWD#/prj}\n",
    "source $SCR/env2/etc/profile.d/conda.sh\n",
    "conda activate $SCR/env2\n",
    "conda activate --stack $SCR/env3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat=1500.0000 | Tempo=6.6508\n",
      "Heat=1500.0000 | Tempo=6.7153\n",
      "Heat=1500.0000 | Tempo=6.5470\n",
      "Heat=1500.0000 | Tempo=6.5648\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python sngr2.py\n",
    "python sngr2.py\n",
    "python sngr2.py\n",
    "python sngr2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNU Fortran (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\n",
      "HYDRA build details:\n",
      "    Version:                                 3.3.2\n",
      "# packages in environment at /scratch/ampemi/eduardo.miranda2/env3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "python                    3.9.4                hdb3f193_0  \n",
      "# packages in environment at /scratch/ampemi/eduardo.miranda2/env2:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "anaconda                  2020.11                  py38_0  \n",
      "python                    3.8.5                h7579374_1  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gfortran --version | head -1\n",
    "mpiexec --version | head -2\n",
    "conda list '^(anaconda|python)$'\n",
    "cd\n",
    "source /scratch${PWD#/prj}/env2/etc/profile.d/conda.sh\n",
    "conda deactivate\n",
    "conda list '^(anaconda|python)$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando em um B715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting st-nu-gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile st-nu-gpu.py\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numba import cuda, jit, prange\n",
    "\n",
    "@cuda.jit\n",
    "def st3(a1, a2):\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = a2[i,j]/2.0+(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1])/8.0\n",
    "\n",
    "def calc3(anew, aold, heat, sizeEnd, niters, nsources, sources, energy,\n",
    "          blocks_per_grid, threads_per_block):\n",
    "    for iters in range(0, niters, 2):\n",
    "        st3[blocks_per_grid, threads_per_block](anew, aold)\n",
    "        for i in range(0, nsources) :\n",
    "            anew[sources[i,0], sources[i,1]] += energy    # heat source\n",
    "        st3[blocks_per_grid, threads_per_block](aold, anew)\n",
    "        for i in range(0, nsources):  \n",
    "            aold[sources[i,0], sources[i,1]] += energy    # heat source        \n",
    "\n",
    "#def par_cuda():\n",
    "n            = 4800    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 500     # number of iterations\n",
    "nsources     = 3       # sources of energy\n",
    "size         = n + 2   # plus the ghost zone\n",
    "sizeEnd      = n + 1\n",
    "\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((size, size), np.float64)\n",
    "aold         = np.zeros((size, size), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3,2), np.int32)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "heat         = 0       # system total heat sum\n",
    "\n",
    "# copy the arrays to the device\n",
    "anew_global_mem = cuda.to_device(anew)\n",
    "aold_global_mem = cuda.to_device(aold)\n",
    "\n",
    "# configure blocks & grids\n",
    "# set the number of threads in a block\n",
    "threads_per_block = (8, 8)\n",
    "# calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "t = time()\n",
    "# main calc\n",
    "calc3(anew_global_mem, aold_global_mem, heat,\n",
    "    sizeEnd, niters, nsources, sources, energy,\n",
    "    blocks_per_grid, threads_per_block)\n",
    "\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "\n",
    "for j in range(1, sizeEnd):\n",
    "    for i in range(1, sizeEnd):\n",
    "        heat = heat + aold[i,j]\n",
    "t = time() - t\n",
    "\n",
    "# show the result if desired\n",
    "print(\"Heat=%.4f | Tempo=%.4f\" % (heat, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "a='/ampemi/eduardo.miranda2/stnc/Numba'\n",
    "s='/prj'$a\n",
    "d='/scratch'$a\n",
    "cp  $s/st-nu-gpu.py  $d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting st-nu-gpu.srm\n"
     ]
    }
   ],
   "source": [
    "%%writefile st-nu-gpu.srm\n",
    "#!/bin/bash\n",
    "# limites das filas (1,0 UA):\n",
    "#   nvidia_dev: 0:20, 1 (24+2), 4 (96+8), 1, 1\n",
    "\n",
    "#SBATCH --ntasks=01            #Total de tarefas\n",
    "#SBATCH -J stnugpu             #Nome do job, 8 caracteres\n",
    "#SBATCH -p nvidia_dev           #Fila (partition) a ser utilizada\n",
    "#SBATCH --time=00:02:00        #Tempo max. de execução 5 minutos\n",
    "#SBATCH --exclusive            #Utilização exclusiva dos nós\n",
    "# #SBATCH --nodes=1              #Qtd de nós\n",
    "# #SBATCH --ntasks-per-node=1    #Qtd de tarefas por nó ($SLURM_NTASKS_PER_NODE)\n",
    "\n",
    "echo '========================================'\n",
    "echo '- Job ID:' $SLURM_JOB_ID\n",
    "echo '- Tarefas por no:' $SLURM_NTASKS_PER_NODE\n",
    "echo '- Qtd. de nos:' $SLURM_JOB_NUM_NODES\n",
    "echo '- Tot. de tarefas:' $SLURM_NTASKS\n",
    "echo '- Nos alocados:' $SLURM_JOB_NODELIST\n",
    "nodeset -e $SLURM_JOB_NODELIST\n",
    "echo '- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):'\n",
    "echo $SLURM_SUBMIT_DIR\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "#echo '-- lscpu ------------------------------'\n",
    "#lscpu\n",
    "#echo '-- meminfo -------------------------'\n",
    "#cat /proc/meminfo | grep MemTotal\n",
    "#echo '-- nvidia-smi ----------------------'\n",
    "#nvidia-smi\n",
    "\n",
    "#Entra no diretório de trabalho\n",
    "d='/scratch/ampemi/eduardo.miranda2/stnc/Numba'\n",
    "cd $d\n",
    "\n",
    "#Modulos\n",
    "#211217: não funciona mais\n",
    "#module load anaconda3/2018.12\n",
    "#conda activate --stack /scratch/ampemi/pedro.santos2/anaconda3/envs/dscience\n",
    "#export NUMBAPRO_NVVM=/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
    "#export NUMBAPRO_LIBDEVICE=/usr/local/cuda-10.1/nvvm/libdevice/\n",
    "DIR=$PWD\n",
    "cd\n",
    "SCR=/scratch${PWD#/prj}\n",
    "source $SCR/env2/etc/profile.d/conda.sh\n",
    "conda activate $SCR/env2\n",
    "conda activate --stack $SCR/env3\n",
    "cd $DIR\n",
    "\n",
    "#Executavel\n",
    "EXEC='python st-nu-gpu.py'\n",
    "\n",
    "#Dispara a execucao\n",
    "echo '-- srun -------------------------------'\n",
    "echo '$ srun -n' $SLURM_NTASKS $EXEC\n",
    "srun -n $SLURM_NTASKS $EXEC\n",
    "echo '-- FIM --------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 787030\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 787030\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3080\n",
      "sdumont3080\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- lscpu ------------------------------\n",
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                24\n",
      "On-line CPU(s) list:   0-23\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    12\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 62\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2695 v2 @ 2.40GHz\n",
      "Stepping:              4\n",
      "CPU MHz:               2400.146\n",
      "CPU max MHz:           2400.0000\n",
      "CPU min MHz:           1200.0000\n",
      "BogoMIPS:              4799.77\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              30720K\n",
      "NUMA node0 CPU(s):     0-11\n",
      "NUMA node1 CPU(s):     12-23\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm epb ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm arat pln pts spec_ctrl intel_stibp flush_l1d\n",
      "-- meminfo -------------------------\n",
      "MemTotal:       65764780 kB\n",
      "-- nvidia-smi ----------------------\n",
      "Tue Dec  1 23:43:16 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K40t          Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    65W / 235W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K40t          Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    65W / 235W |      0MiB / 11441MiB |     69%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "Heat=1500.0000 | Tempo=25.4509\n",
      "-- FIM --------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "d='/scratch/ampemi/eduardo.miranda2/stnc/Numba'\n",
    "cat $d/slurm-787030.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting st-nu-gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile st-nu-gpu.py\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numba import cuda, jit, prange\n",
    "\n",
    "@cuda.jit\n",
    "def st3(a1, a2):\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = a2[i,j]/2.0+(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1])/8.0\n",
    "\n",
    "def calc3(anew, aold, heat, sizeEnd, niters, nsources, sources, energy,\n",
    "          blocks_per_grid, threads_per_block):\n",
    "    for iters in range(0, niters, 2):\n",
    "        st3[blocks_per_grid, threads_per_block](anew, aold)\n",
    "        for i in range(0, nsources) :\n",
    "            anew[sources[i,0], sources[i,1]] += energy    # heat source\n",
    "        st3[blocks_per_grid, threads_per_block](aold, anew)\n",
    "        for i in range(0, nsources):  \n",
    "            aold[sources[i,0], sources[i,1]] += energy    # heat source        \n",
    "\n",
    "#def par_cuda():\n",
    "n            = 4800    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 500     # number of iterations\n",
    "nsources     = 3       # sources of energy\n",
    "size         = n + 2   # plus the ghost zone\n",
    "sizeEnd      = n + 1\n",
    "\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((size, size), np.float64)\n",
    "aold         = np.zeros((size, size), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3,2), np.int32)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "heat         = 0       # system total heat sum\n",
    "\n",
    "# copy the arrays to the device\n",
    "anew_global_mem = cuda.to_device(anew)\n",
    "aold_global_mem = cuda.to_device(aold)\n",
    "\n",
    "# configure blocks & grids\n",
    "# set the number of threads in a block\n",
    "threads_per_block = (16, 16)\n",
    "# calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "t = time()\n",
    "# main calc\n",
    "calc3(anew_global_mem, aold_global_mem, heat,\n",
    "    sizeEnd, niters, nsources, sources, energy,\n",
    "    blocks_per_grid, threads_per_block)\n",
    "\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "\n",
    "for j in range(1, sizeEnd):\n",
    "    for i in range(1, sizeEnd):\n",
    "        heat = heat + aold[i,j]\n",
    "t = time() - t\n",
    "\n",
    "# show the result if desired\n",
    "print(\"Heat=%.4f | Tempo=%.4f\" % (heat, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 787034\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "            787034 nvidia_de  stnugpu eduardo.  R       0:00      1 sdumont3080\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 787034\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3080\n",
      "sdumont3080\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- lscpu ------------------------------\n",
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                24\n",
      "On-line CPU(s) list:   0-23\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    12\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 62\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2695 v2 @ 2.40GHz\n",
      "Stepping:              4\n",
      "CPU MHz:               2400.146\n",
      "CPU max MHz:           2400.0000\n",
      "CPU min MHz:           1200.0000\n",
      "BogoMIPS:              4799.77\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              30720K\n",
      "NUMA node0 CPU(s):     0-11\n",
      "NUMA node1 CPU(s):     12-23\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm epb ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm arat pln pts spec_ctrl intel_stibp flush_l1d\n",
      "-- meminfo -------------------------\n",
      "MemTotal:       65764780 kB\n",
      "-- nvidia-smi ----------------------\n",
      "Tue Dec  1 23:52:13 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K40t          Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    65W / 235W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K40t          Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    64W / 235W |      0MiB / 11441MiB |     56%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "Heat=1500.0000 | Tempo=22.2789\n",
      "-- FIM --------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "d='/scratch/ampemi/eduardo.miranda2/stnc/Numba'\n",
    "cat $d/slurm-787034.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 211217 rodando 4x no B715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10350748\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n",
      "2021-12-17T18:09:57  10350748  nvidia_dev stnug   R  0:04     1   24\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 10350748\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3091\n",
      "sdumont3091\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- lscpu ------------------------------\n",
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                24\n",
      "On-line CPU(s) list:   0-23\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    12\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 62\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2695 v2 @ 2.40GHz\n",
      "Stepping:              4\n",
      "CPU MHz:               2088.134\n",
      "CPU max MHz:           2400,0000\n",
      "CPU min MHz:           1200,0000\n",
      "BogoMIPS:              4800.12\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              30720K\n",
      "NUMA node0 CPU(s):     0-11\n",
      "NUMA node1 CPU(s):     12-23\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm epb ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm arat pln pts spec_ctrl intel_stibp flush_l1d\n",
      "-- meminfo -------------------------\n",
      "MemTotal:       65764776 kB\n",
      "-- nvidia-smi ----------------------\n",
      "Fri Dec 17 18:09:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K40t          On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   40C    P8    20W / 235W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K40t          On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P8    21W / 235W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "Heat=1500.0000 | Tempo=19.2523\n",
      "-- FIM --------------------------------\n"
     ]
    }
   ],
   "source": [
    "! cat /scratch${PWD#/prj}/slurm-10350748.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10350749\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n",
      "2021-12-17T18:13:04  10350749  nvidia_dev stnug   R  0:00     1   24\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 10350749\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3091\n",
      "sdumont3091\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "Heat=1500.0000 | Tempo=17.3833\n",
      "-- FIM --------------------------------\n"
     ]
    }
   ],
   "source": [
    "! cat /scratch${PWD#/prj}/slurm-10350749.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10350751\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n",
      "2021-12-17T18:14:07  10350751  nvidia_dev stnug   R  0:00     1   24\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 10350751\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3091\n",
      "sdumont3091\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "Heat=1500.0000 | Tempo=21.7487\n",
      "-- FIM --------------------------------\n"
     ]
    }
   ],
   "source": [
    "! cat /scratch${PWD#/prj}/slurm-10350751.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10350772\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n",
      "2021-12-17T18:15:27  10350772  nvidia_dev stnug   R  0:00     1   24\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         START_TIME     JOBID   PARTITION  NAME  ST  TIME NODES CPUS\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu --format \"%.19S  %.8i  %.10P %.5j  %.2t %.5M %.5D %.4C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 10350772\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3091\n",
      "sdumont3091\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "Heat=1500.0000 | Tempo=16.1785\n",
      "-- FIM --------------------------------\n"
     ]
    }
   ],
   "source": [
    "! cat /scratch${PWD#/prj}/slurm-10350772.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando 32x32 thread block size\n",
    "não funcionou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting st-nu-gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile st-nu-gpu.py\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numba import cuda, jit, prange\n",
    "\n",
    "@cuda.jit\n",
    "def st3(a1, a2):\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = a2[i,j]/2.0+(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1])/8.0\n",
    "\n",
    "def calc3(anew, aold, heat, sizeEnd, niters, nsources, sources, energy,\n",
    "          blocks_per_grid, threads_per_block):\n",
    "    for iters in range(0, niters, 2):\n",
    "        st3[blocks_per_grid, threads_per_block](anew, aold)\n",
    "        for i in range(0, nsources) :\n",
    "            anew[sources[i,0], sources[i,1]] += energy    # heat source\n",
    "        st3[blocks_per_grid, threads_per_block](aold, anew)\n",
    "        for i in range(0, nsources):  \n",
    "            aold[sources[i,0], sources[i,1]] += energy    # heat source        \n",
    "\n",
    "#def par_cuda():\n",
    "n            = 4800    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 500     # number of iterations\n",
    "nsources     = 3       # sources of energy\n",
    "size         = n + 2   # plus the ghost zone\n",
    "sizeEnd      = n + 1\n",
    "\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((size, size), np.float64)\n",
    "aold         = np.zeros((size, size), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3,2), np.int32)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "heat         = 0       # system total heat sum\n",
    "\n",
    "# copy the arrays to the device\n",
    "anew_global_mem = cuda.to_device(anew)\n",
    "aold_global_mem = cuda.to_device(aold)\n",
    "\n",
    "# configure blocks & grids\n",
    "# set the number of threads in a block\n",
    "threads_per_block = (32, 32)\n",
    "# calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "t = time()\n",
    "# main calc\n",
    "calc3(anew_global_mem, aold_global_mem, heat,\n",
    "    sizeEnd, niters, nsources, sources, energy,\n",
    "    blocks_per_grid, threads_per_block)\n",
    "\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "\n",
    "for j in range(1, sizeEnd):\n",
    "    for i in range(1, sizeEnd):\n",
    "        heat = heat + aold[i,j]\n",
    "t = time() - t\n",
    "\n",
    "# show the result if desired\n",
    "print(\"Heat=%.4f | Tempo=%.4f\" % (heat, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 787898\n"
     ]
    }
   ],
   "source": [
    "! sbatch st-nu-gpu.srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "            787898 nvidia_de  stnugpu eduardo.  R       0:03      1 sdumont3030\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "! squeue -n stnugpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "- Job ID: 787898\n",
      "- Tarefas por no:\n",
      "- Qtd. de nos: 1\n",
      "- Tot. de tarefas: 1\n",
      "- Nos alocados: sdumont3030\n",
      "sdumont3030\n",
      "- diretorio onde sbatch foi chamado ($SLURM_SUBMIT_DIR):\n",
      "/prj/ampemi/eduardo.miranda2/stnc/Numba\n",
      "-- lscpu ------------------------------\n",
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                24\n",
      "On-line CPU(s) list:   0-23\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    12\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 62\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2695 v2 @ 2.40GHz\n",
      "Stepping:              4\n",
      "CPU MHz:               2400.146\n",
      "CPU max MHz:           2400.0000\n",
      "CPU min MHz:           1200.0000\n",
      "BogoMIPS:              4800.39\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              30720K\n",
      "NUMA node0 CPU(s):     0-11\n",
      "NUMA node1 CPU(s):     12-23\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm epb ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm arat pln pts spec_ctrl intel_stibp flush_l1d\n",
      "-- meminfo -------------------------\n",
      "MemTotal:       65764780 kB\n",
      "-- nvidia-smi ----------------------\n",
      "Wed Dec  2 13:34:46 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K40t          Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    62W / 235W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K40t          Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    63W / 235W |      0MiB / 11441MiB |     34%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "-- srun -------------------------------\n",
      "$ srun -n 1 python st-nu-gpu.py\n",
      "slurmstepd: error: *** STEP 787898.0 ON sdumont3030 CANCELLED AT 2020-12-02T13:36:43 DUE TO TIME LIMIT ***\n",
      "slurmstepd: error: *** JOB 787898 ON sdumont3030 CANCELLED AT 2020-12-02T13:36:43 DUE TO TIME LIMIT ***\n",
      "srun: Job step aborted: Waiting up to 302 seconds for job step to finish.\n",
      "srun: got SIGCONT\n",
      "srun: forcing job termination\n",
      "srun: error: sdumont3030: task 0: Terminated\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "d='/scratch/ampemi/eduardo.miranda2/stnc/Numba'\n",
    "cat $d/slurm-787898.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
