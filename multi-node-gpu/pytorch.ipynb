{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch multi-GPU and multi-node\n",
    "\n",
    "*Last edited: 2022-04-09*\n",
    "\n",
    "Example of training a convolutional neural network using the MNIST database. Uses multi-GPU and multi-node data parallelism running on the LNCC Santos Dumont supercomputer.\n",
    "\n",
    "Adapted from IDRIS: http://www.idris.fr/eng/jean-zay/gpu/jean-zay-gpu-torch-multi-eng.html (please follow this link to find the documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;background-color:red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we are runnin on the node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdumont18\n"
     ]
    }
   ],
   "source": [
    "! hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Modulefiles Currently Loaded.\n"
     ]
    }
   ],
   "source": [
    "! module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyTorch checkpoints: <http://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /scratch${PWD#/prj}\n",
    "mkdir -p checkpoint\n",
    "rm -f checkpoint/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yyyy/xxxx/pytorch\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539871ddc68f4e21bd3a4bf4ce7f5538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting /scratch/yyyy/xxxx/pytorch/MNIST/raw/train-images-idx3-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e851408e4d7e4a638d4561ec751c2142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting /scratch/yyyy/xxxx/pytorch/MNIST/raw/train-labels-idx1-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854d516e959a4835bab6b30110acde08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting /scratch/yyyy/xxxx/pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a151778b5948ebbe923ee77ad091a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting /scratch/yyyy/xxxx/pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz to /scratch/yyyy/xxxx/pytorch/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /scratch/yyyy/xxxx/pytorch\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, torchvision, torchvision.transforms as transforms\n",
    "\n",
    "SCRATCH = os.environ['PWD'].replace('/prj/', '/scratch/') + '/pytorch'\n",
    "os.environ['SCRATCH'] = SCRATCH\n",
    "print(SCRATCH)\n",
    "\n",
    "torchvision.datasets.MNIST(root=SCRATCH,\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist-distributed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist-distributed.py \n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import argparse\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import sdenv\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-b', '--batch-size', default=128, type =int,\n",
    "        help='batch size. it will be divided in mini-batch for each worker')\n",
    "    parser.add_argument('-e','--epochs', default=2, type=int, metavar='N',\n",
    "        help='number of total epochs to run')\n",
    "    parser.add_argument('-c','--checkpoint', default=None, type=str,\n",
    "        help='path to checkpoint to load')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train(args)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mnist-distributed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a mnist-distributed.py\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mnist-distributed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a mnist-distributed.py\n",
    "\n",
    "def train(args):\n",
    "    # NCCL itâ€™s the only backend that currently supports InfiniBand\n",
    "    # and GPUDirect.\n",
    "    # Configure distribution method: define address and port of the \n",
    "    # master node and initialise communication backend (NCCL).\n",
    "    # init_method='env://',\n",
    "    # init_method=sdenv.MASTER_TCP,\n",
    "    dist.init_process_group(\n",
    "        backend = 'nccl',\n",
    "        init_method = 'env://',\n",
    "        world_size=sdenv.size, \n",
    "        rank=sdenv.rank\n",
    "    )\n",
    "    \n",
    "    # distribute model\n",
    "    torch.cuda.set_device(sdenv.local_rank)\n",
    "    gpu = torch.device(\"cuda\")\n",
    "    model = ConvNet().to(gpu)\n",
    "    ddp_model = DistributedDataParallel(\n",
    "        model, \n",
    "        device_ids=[sdenv.local_rank])\n",
    "    if args.checkpoint is not None:\n",
    "        map_location = {'cuda:%d' % 0: 'cuda:%d' % sdenv.local_rank}\n",
    "        ddp_model.load_state_dict(\n",
    "            torch.load(args.checkpoint, map_location=map_location))\n",
    "    \n",
    "    # distribute batch size (mini-batch)\n",
    "    batch_size = args.batch_size \n",
    "    batch_size_per_gpu = batch_size // sdenv.size\n",
    "    \n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.SGD(ddp_model.parameters(), 1e-4)\n",
    "\n",
    "    # load data with distributed sampler\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=os.environ['DSDIR'],\n",
    "        train=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=False)\n",
    "    \n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas=sdenv.size,\n",
    "        rank=sdenv.rank)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size_per_gpu,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    # training (timers and display handled by process 0)\n",
    "    if sdenv.rank == 0: \n",
    "        start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        if sdenv.rank == 0: start_dataload = time()\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # distribution of images and labels to all GPUs\n",
    "            images = images.to(gpu, non_blocking=True)\n",
    "            labels = labels.to(gpu, non_blocking=True) \n",
    "            \n",
    "            if sdenv.rank == 0: stop_dataload = time()\n",
    "\n",
    "            if sdenv.rank == 0: start_training = time()\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = ddp_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if sdenv.rank == 0: \n",
    "                stop_training = time() \n",
    "            if (i + 1) % 200 == 0 and sdenv.rank == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time data load: {:.3f}ms, Time training: {:.3f}ms'\\\n",
    "                      .format(epoch + 1, \n",
    "                              args.epochs, \n",
    "                              i + 1, \n",
    "                              total_step, \n",
    "                              loss.item(), \n",
    "                              (stop_dataload - start_dataload)*1000,\n",
    "                              (stop_training - start_training)*1000))\n",
    "            if sdenv.rank == 0: start_dataload = time()\n",
    "                    \n",
    "        #Save checkpoint at every end of epoch\n",
    "        if sdenv.rank == 0:\n",
    "            torch.save(\n",
    "                ddp_model.state_dict(), \n",
    "                './checkpoint/{}GPU_{}epoch.checkpoint'.format(sdenv.size, epoch+1))\n",
    "\n",
    "    if sdenv.rank == 0:\n",
    "        print(\">>> Training complete in: \"+str(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mnist-distributed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a mnist-distributed.py\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    # display info\n",
    "    if sdenv.rank == 0:\n",
    "        print(\">>> Training on \", len(sdenv.hostnames), \n",
    "              \" nodes and \", sdenv.size, \n",
    "              \" processes, master node is \", sdenv.MASTER_ADDR)\n",
    "    print(\"- Process {} corresponds to GPU {} of node {}\"\\\n",
    "          .format(sdenv.rank, \n",
    "          sdenv.local_rank, \n",
    "          sdenv.node_rank))\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "BASE=/scratch${PWD#/prj}\n",
    "cp mnist-distributed.py sdenv.py $BASE\n",
    "mkdir -p $BASE/checkpoint\n",
    "rm -f $BASE/checkpoint/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the version of PyTorch I'm using doesn't work on K40's from B715, it says it's not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting monogpu.srm\n"
     ]
    }
   ],
   "source": [
    "%%writefile monogpu.srm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name monogpu              # SLURM_JOB_NAME\n",
    "#SBATCH --partition sequana_gpu_shared  # SLURM_JOB_PARTITION\n",
    "#SBATCH --nodes=1                       # SLURM_JOB_NUM_NODES\n",
    "#SBATCH --ntasks-per-node=1             # SLURM_NTASKS_PER_NODE\n",
    "#SBATCH --cpus-per-task=10              # SLURM_CPUS_PER_TASK\n",
    "#SBATCH --time=00:10:00                 # Limit execution time\n",
    "\n",
    "# VARIABLES OF INTEREST IN THE SLURM ENVIRONMENT\n",
    "# <https://slurm.schedmd.com/sbatch.html>\n",
    "# SLURM_PROCID\n",
    "#     The MPI rank (or relative process ID) of the current process.\n",
    "# SLURM_LOCALID\n",
    "#     Node local task ID for the process within a job.\n",
    "# SLURM_NODEID\n",
    "#     ID of the nodes allocated. \n",
    "\n",
    "echo '========================================'\n",
    "echo '- Job ID:' $SLURM_JOB_ID\n",
    "echo '- # of nodes in the job:' $SLURM_JOB_NUM_NODES\n",
    "echo '- # of tasks per node:' $SLURM_NTASKS_PER_NODE\n",
    "echo '- # of tasks:' $SLURM_NTASKS\n",
    "echo '- # of cpus per task:' $SLURM_CPUS_PER_TASK\n",
    "echo '- Dir from which sbatch was invoked:' ${SLURM_SUBMIT_DIR##*/}\n",
    "echo -n '- Nodes allocated to the job: '\n",
    "nodeset -e $SLURM_JOB_NODELIST\n",
    "\n",
    "# go to the work directory from which sbatch was invoked\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "module load sequana/current\n",
    "module load cuda/10.2                                              \n",
    "                                              \n",
    "# load the Python environment\n",
    "SCR=/scratch${PWD#/prj}\n",
    "BASE=/scratch${HOME#/prj}\n",
    "ENV=miniconda\n",
    "source $BASE/$ENV/etc/profile.d/conda.sh\n",
    "conda activate $BASE/$ENV\n",
    "cd $SCR\n",
    "\n",
    "# run\n",
    "echo -n '<1. starting python script > ' && date\n",
    "echo '-- output -----------------------------'\n",
    "\n",
    "srun  python  -u mnist-distributed.py  --epochs 8  --batch-size 128\n",
    "\n",
    "echo '-- end --------------------------------'\n",
    "echo -n '<2. quit>                    ' && date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10474458\n",
      "========================================\n",
      "- Job ID: 10474458\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks per node: 1\n",
      "- # of tasks: 1\n",
      "- # of cpus per task: 10\n",
      "- Dir from which sbatch was invoked: pt\n",
      "- Nodes allocated to the job: sdumont8033\n",
      "<1. starting python script > Qui Mar 24 20:24:52 -03 2022\n",
      "-- output -----------------------------\n",
      ">>> Training on  1  nodes and  1  processes, master node is  172.20.15.34\n",
      "- Process 0 corresponds to GPU 0 of node 0\n",
      "[W socket.cpp:401] [c10d] The server socket cannot be initialized on [::]:20324 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:20324 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:20324 (errno: 97 - Address family not supported by protocol).\n",
      "Epoch [1/8], Step [200/469], Loss: 2.0588, Time data load: 7.616ms, Time training: 1.623ms\n",
      "Epoch [1/8], Step [400/469], Loss: 1.8388, Time data load: 7.644ms, Time training: 1.621ms\n",
      "Epoch [2/8], Step [200/469], Loss: 1.5578, Time data load: 7.625ms, Time training: 1.604ms\n",
      "Epoch [2/8], Step [400/469], Loss: 1.4029, Time data load: 7.627ms, Time training: 1.615ms\n",
      "Epoch [3/8], Step [200/469], Loss: 1.2119, Time data load: 7.881ms, Time training: 1.622ms\n",
      "Epoch [3/8], Step [400/469], Loss: 1.1195, Time data load: 7.603ms, Time training: 1.625ms\n",
      "Epoch [4/8], Step [200/469], Loss: 0.9791, Time data load: 7.650ms, Time training: 1.613ms\n",
      "Epoch [4/8], Step [400/469], Loss: 0.9316, Time data load: 7.617ms, Time training: 1.616ms\n",
      "Epoch [5/8], Step [200/469], Loss: 0.8212, Time data load: 7.634ms, Time training: 1.628ms\n",
      "Epoch [5/8], Step [400/469], Loss: 0.8014, Time data load: 7.634ms, Time training: 1.603ms\n",
      "Epoch [6/8], Step [200/469], Loss: 0.7091, Time data load: 7.605ms, Time training: 1.597ms\n",
      "Epoch [6/8], Step [400/469], Loss: 0.7064, Time data load: 7.709ms, Time training: 1.604ms\n",
      "Epoch [7/8], Step [200/469], Loss: 0.6264, Time data load: 7.594ms, Time training: 1.606ms\n",
      "Epoch [7/8], Step [400/469], Loss: 0.6340, Time data load: 14.789ms, Time training: 2.376ms\n",
      "Epoch [8/8], Step [200/469], Loss: 0.5629, Time data load: 7.595ms, Time training: 1.601ms\n",
      "Epoch [8/8], Step [400/469], Loss: 0.5771, Time data load: 7.572ms, Time training: 1.603ms\n",
      ">>> Training complete in: 0:00:36.528605\n",
      "-- end --------------------------------\n",
      "<2. quit>                    Qui Mar 24 20:25:45 -03 2022\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = !sbatch monogpu.srm\n",
    "print(a[0])\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    b = ! squeue --user $USER --name=monogpu\n",
    "    if len(b) < 2: break\n",
    "b = !echo /scratch${PWD#/prj}/slurm-\n",
    "%cat {b[0]+a[0].replace('Submitted batch job ','')}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;background-color:red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of multi-GPU mono-node execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mononode.srm\n"
     ]
    }
   ],
   "source": [
    "%%writefile mononode.srm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name mononode             # SLURM_JOB_NAME\n",
    "#SBATCH --partition sequana_gpu_shared  # SLURM_JOB_PARTITION\n",
    "#SBATCH --nodes=1                       # SLURM_JOB_NUM_NODES\n",
    "#SBATCH --ntasks-per-node=4             # SLURM_NTASKS_PER_NODE\n",
    "#SBATCH --cpus-per-task=10              # SLURM_CPUS_PER_TASK\n",
    "#SBATCH --time=00:10:00                 # Limit execution time\n",
    "\n",
    "# VARIABLES OF INTEREST IN THE SLURM ENVIRONMENT\n",
    "# <https://slurm.schedmd.com/sbatch.html>\n",
    "# SLURM_PROCID\n",
    "#     The MPI rank (or relative process ID) of the current process.\n",
    "# SLURM_LOCALID\n",
    "#     Node local task ID for the process within a job.\n",
    "# SLURM_NODEID\n",
    "#     ID of the nodes allocated. \n",
    "\n",
    "echo '========================================'\n",
    "echo '- Job ID:' $SLURM_JOB_ID\n",
    "echo '- # of nodes in the job:' $SLURM_JOB_NUM_NODES\n",
    "echo '- # of tasks per node:' $SLURM_NTASKS_PER_NODE\n",
    "echo '- # of tasks:' $SLURM_NTASKS\n",
    "echo '- # of cpus per task:' $SLURM_CPUS_PER_TASK\n",
    "echo '- Dir from which sbatch was invoked:' ${SLURM_SUBMIT_DIR##*/}\n",
    "echo -n '- Nodes allocated to the job: '\n",
    "nodeset -e $SLURM_JOB_NODELIST\n",
    "\n",
    "# go to the work directory from which sbatch was invoked\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "# load the Python environment\n",
    "SCR=/scratch${PWD#/prj}\n",
    "BASE=/scratch${HOME#/prj}\n",
    "source $BASE/env2/etc/profile.d/conda.sh\n",
    "conda activate $BASE/env2\n",
    "cd $SCR\n",
    "\n",
    "# run\n",
    "echo -n '<1. starting python script > ' && date\n",
    "echo '-- output -----------------------------'\n",
    "\n",
    "srun python -u mnist-distributed.py --epochs 8 --batch-size 128\n",
    "\n",
    "echo '-- end --------------------------------'\n",
    "echo -n '<2. quit>                    ' && date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10473923\n",
      "========================================\n",
      "- Job ID: 10473923\n",
      "- # of nodes in the job: 1\n",
      "- # of tasks per node: 4\n",
      "- # of tasks: 4\n",
      "- # of cpus per task: 10\n",
      "- Dir from which sbatch was invoked: pytorch\n",
      "- Nodes allocated to the job: sdumont8037\n",
      "which: no fi_info in (/scratch/yyyy/xxxx/env2/bin:/scratch/yyyy/xxxx/env2/condabin:/opt/xcs/App/Scripts:/specific/bin:/specific/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/xcs/Admin/Scripts:/prj/yyyy/xxxx/.local/bin:/prj/yyyy/xxxx/bin)\n",
      "<1. starting python script > Qui Mar 24 11:42:10 -03 2022\n",
      "-- output -----------------------------\n",
      "- Process 1 corresponds to GPU 1 of node 0\n",
      "- Process 2 corresponds to GPU 2 of node 0\n",
      "- Process 3 corresponds to GPU 3 of node 0\n",
      ">>> Training on  1  nodes and  4  processes, master node is  sdumont8037\n",
      "- Process 0 corresponds to GPU 0 of node 0\n",
      "[W socket.cpp:401] [c10d] The server socket cannot be initialized on [::]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8037-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "Epoch [1/8], Step [200/469], Loss: 2.0488, Time data load: 2.833ms, Time training: 2.358ms\n",
      "Epoch [1/8], Step [400/469], Loss: 1.6635, Time data load: 2.213ms, Time training: 1.973ms\n",
      "Epoch [2/8], Step [200/469], Loss: 1.5600, Time data load: 2.194ms, Time training: 1.765ms\n",
      "Epoch [2/8], Step [400/469], Loss: 1.2515, Time data load: 2.174ms, Time training: 1.749ms\n",
      "Epoch [3/8], Step [200/469], Loss: 1.2295, Time data load: 2.204ms, Time training: 1.741ms\n",
      "Epoch [3/8], Step [400/469], Loss: 1.0056, Time data load: 2.144ms, Time training: 1.900ms\n",
      "Epoch [4/8], Step [200/469], Loss: 1.0068, Time data load: 2.169ms, Time training: 1.886ms\n",
      "Epoch [4/8], Step [400/469], Loss: 0.8471, Time data load: 2.082ms, Time training: 1.797ms\n",
      "Epoch [5/8], Step [200/469], Loss: 0.8510, Time data load: 2.178ms, Time training: 1.854ms\n",
      "Epoch [5/8], Step [400/469], Loss: 0.7364, Time data load: 2.150ms, Time training: 1.760ms\n",
      "Epoch [6/8], Step [200/469], Loss: 0.7371, Time data load: 2.175ms, Time training: 1.771ms\n",
      "Epoch [6/8], Step [400/469], Loss: 0.6546, Time data load: 2.250ms, Time training: 1.740ms\n",
      "Epoch [7/8], Step [200/469], Loss: 0.6512, Time data load: 2.206ms, Time training: 1.928ms\n",
      "Epoch [7/8], Step [400/469], Loss: 0.5922, Time data load: 2.229ms, Time training: 1.868ms\n",
      "Epoch [8/8], Step [200/469], Loss: 0.5847, Time data load: 2.178ms, Time training: 1.879ms\n",
      "Epoch [8/8], Step [400/469], Loss: 0.5429, Time data load: 2.112ms, Time training: 1.849ms\n",
      ">>> Training complete in: 0:00:17.219894\n",
      "-- end --------------------------------\n",
      "<2. quit>                    Qui Mar 24 11:43:38 -03 2022\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = !sbatch mononode.srm\n",
    "print(a[0])\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    b = ! squeue --user $USER --name=mononode\n",
    "    if len(b) < 2: break\n",
    "b = !echo /scratch${PWD#/prj}/slurm-\n",
    "%cat {b[0]+a[0].replace('Submitted batch job ','')}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;background-color:red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of multi-GPU multi-node execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing multinode.srm\n"
     ]
    }
   ],
   "source": [
    "%%writefile multinode.srm\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name multinode            # SLURM_JOB_NAME\n",
    "#SBATCH --partition sequana_gpu_shared  # SLURM_JOB_PARTITION\n",
    "#SBATCH --nodes=3                       # SLURM_JOB_NUM_NODES\n",
    "#SBATCH --ntasks-per-node=4             # SLURM_NTASKS_PER_NODE\n",
    "#SBATCH --cpus-per-task=10              # SLURM_CPUS_PER_TASK\n",
    "#SBATCH --time=00:10:00                 # Limit execution time\n",
    "\n",
    "# VARIABLES OF INTEREST IN THE SLURM ENVIRONMENT\n",
    "# <https://slurm.schedmd.com/sbatch.html>\n",
    "# SLURM_PROCID\n",
    "#     The MPI rank (or relative process ID) of the current process.\n",
    "# SLURM_LOCALID\n",
    "#     Node local task ID for the process within a job.\n",
    "# SLURM_NODEID\n",
    "#     ID of the nodes allocated. \n",
    "\n",
    "echo '========================================'\n",
    "echo '- Job ID:' $SLURM_JOB_ID\n",
    "echo '- # of nodes in the job:' $SLURM_JOB_NUM_NODES\n",
    "echo '- # of tasks per node:' $SLURM_NTASKS_PER_NODE\n",
    "echo '- # of tasks:' $SLURM_NTASKS\n",
    "echo '- # of cpus per task:' $SLURM_CPUS_PER_TASK\n",
    "echo '- Dir from which sbatch was invoked:' ${SLURM_SUBMIT_DIR##*/}\n",
    "echo -n '- Nodes allocated to the job: '\n",
    "nodeset -e $SLURM_JOB_NODELIST\n",
    "\n",
    "# go to the work directory from which sbatch was invoked\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "# load the Python environment\n",
    "SCR=/scratch${PWD#/prj}\n",
    "BASE=/HOME${PWD#/prj}\n",
    "source $BASE/env2/etc/profile.d/conda.sh\n",
    "conda activate $BASE/env2\n",
    "cd $SCR\n",
    "\n",
    "# run\n",
    "echo -n '<1. starting python script > ' && date\n",
    "echo '-- output -----------------------------'\n",
    "\n",
    "srun python -u mnist-distributed.py --epochs 8 --batch-size 128\n",
    "\n",
    "echo '-- end --------------------------------'\n",
    "echo -n '<2. quit>                    ' && date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10473925\n",
      "========================================\n",
      "- Job ID: 10473925\n",
      "- # of nodes in the job: 3\n",
      "- # of tasks per node: 4\n",
      "- # of tasks: 12\n",
      "- # of cpus per task: 10\n",
      "- Dir from which sbatch was invoked: pytorch\n",
      "- Nodes allocated to the job: sdumont8033 sdumont8034 sdumont8037\n",
      "which: no fi_info in (/scratch/yyyy/xxxx/env2/bin:/scratch/yyyy/xxxx/env2/condabin:/opt/xcs/App/Scripts:/specific/bin:/specific/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/xcs/Admin/Scripts:/prj/yyyy/xxxx/.local/bin:/prj/yyyy/xxxx/bin)\n",
      "<1. starting python script > Qui Mar 24 11:51:58 -03 2022\n",
      "-- output -----------------------------\n",
      "- Process 6 corresponds to GPU 2 of node 1\n",
      "- Process 8 corresponds to GPU 0 of node 2\n",
      "- Process 1 corresponds to GPU 1 of node 0\n",
      "- Process 10 corresponds to GPU 2 of node 2\n",
      "- Process 7 corresponds to GPU 3 of node 1\n",
      "- Process 9 corresponds to GPU 1 of node 2\n",
      "- Process 5 corresponds to GPU 1 of node 1\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "- Process 11 corresponds to GPU 3 of node 2\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "- Process 4 corresponds to GPU 0 of node 1\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "- Process 2 corresponds to GPU 2 of node 0\n",
      "- Process 3 corresponds to GPU 3 of node 0\n",
      ">>> Training on  3  nodes and  12  processes, master node is  sdumont8033\n",
      "- Process 0 corresponds to GPU 0 of node 0\n",
      "[W socket.cpp:401] [c10d] The server socket cannot be initialized on [::]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [sdumont8033-ic1]:9000 (errno: 97 - Address family not supported by protocol).\n",
      "Epoch [1/8], Step [200/500], Loss: 1.9922, Time data load: 0.863ms, Time training: 1.913ms\n",
      "Epoch [1/8], Step [400/500], Loss: 1.7037, Time data load: 0.870ms, Time training: 1.870ms\n",
      "Epoch [2/8], Step [200/500], Loss: 1.5321, Time data load: 0.849ms, Time training: 1.869ms\n",
      "Epoch [2/8], Step [400/500], Loss: 1.1950, Time data load: 0.837ms, Time training: 1.848ms\n",
      "Epoch [3/8], Step [200/500], Loss: 1.2313, Time data load: 0.856ms, Time training: 2.258ms\n",
      "Epoch [3/8], Step [400/500], Loss: 0.9040, Time data load: 0.855ms, Time training: 1.727ms\n",
      "Epoch [4/8], Step [200/500], Loss: 1.0363, Time data load: 0.866ms, Time training: 2.104ms\n",
      "Epoch [4/8], Step [400/500], Loss: 0.7289, Time data load: 0.879ms, Time training: 2.209ms\n",
      "Epoch [5/8], Step [200/500], Loss: 0.9008, Time data load: 0.872ms, Time training: 1.806ms\n",
      "Epoch [5/8], Step [400/500], Loss: 0.6140, Time data load: 0.862ms, Time training: 1.847ms\n",
      "Epoch [6/8], Step [200/500], Loss: 0.8008, Time data load: 0.847ms, Time training: 1.894ms\n",
      "Epoch [6/8], Step [400/500], Loss: 0.5323, Time data load: 0.844ms, Time training: 1.801ms\n",
      "Epoch [7/8], Step [200/500], Loss: 0.7225, Time data load: 0.830ms, Time training: 1.841ms\n",
      "Epoch [7/8], Step [400/500], Loss: 0.4718, Time data load: 0.860ms, Time training: 1.866ms\n",
      "Epoch [8/8], Step [200/500], Loss: 0.6597, Time data load: 0.853ms, Time training: 1.899ms\n",
      "Epoch [8/8], Step [400/500], Loss: 0.4251, Time data load: 0.852ms, Time training: 2.095ms\n",
      ">>> Training complete in: 0:00:13.589709\n",
      "-- end --------------------------------\n",
      "<2. quit>                    Qui Mar 24 11:53:23 -03 2022\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = !sbatch multinode.srm\n",
    "print(a[0])\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    b = ! squeue --user $USER --name=multinode\n",
    "    if len(b) < 2: break\n",
    "b = !echo /scratch${PWD#/prj}/slurm-\n",
    "%cat {b[0]+a[0].replace('Submitted batch job ','')}.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
